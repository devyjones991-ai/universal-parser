from __future__ import annotations

import asyncio
import json
import io

import pandas as pd
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import BufferedInputFile
from config import settings, parsing_profiles
from parser import UniversalParser
from db import get_recent_results, save_results
from alerts.checker import AlertChecker

alert_checker = AlertChecker()

bot = Bot(token=settings.TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–∞
def is_admin(user_id: int) -> bool:
    return user_id == settings.TELEGRAM_CHAT_ID or user_id in settings.ADMIN_CHAT_IDS

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    if not is_admin(message.from_user.id):
        await message.reply("‚ùå –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω")
        return
    
    await message.reply(
        "üöÄ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –∑–∞–ø—É—â–µ–Ω!\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/profiles - —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ñ–∏–ª–µ–π\n"
        "/parse <url> - –ø–∞—Ä—Å–∏—Ç—å URL\n"
        "/run <profile> - –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å\n"
        "/results - –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n"
        "/export - —ç–∫—Å–ø–æ—Ä—Ç –≤ Excel/CSV\n"
        "/news [niche] [region] - —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏\n"
        "/digest [niche] [region] - –¥–∞–π–¥–∂–µ—Å—Ç\n"
        "/directory <type> [niche] [region] - —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏"
    )


def _parse_filters(message_text: str) -> dict:
    tokens = message_text.split()[1:]
    filters = {"niche": "all", "region": "all"}
    positional_order = ["niche", "region"]
    position = 0

    for token in tokens:
        if "=" in token:
            key, value = token.split("=", 1)
            key = key.lower()
            if key in filters:
                filters[key] = value
        else:
            if position < len(positional_order):
                filters[positional_order[position]] = token
                position += 1
    return filters


def _parse_directory_args(message_text: str) -> tuple[str, dict]:
    tokens = message_text.split()[1:]
    entry_type = "supplier"
    filters = {"niche": "all", "region": "all"}
    positional_order = ["niche", "region"]
    position = 0

    if tokens and "=" not in tokens[0]:
        entry_type = tokens[0]
        tokens = tokens[1:]

    for token in tokens:
        if "=" in token:
            key, value = token.split("=", 1)
            key = key.lower()
            if key in filters:
                filters[key] = value
        else:
            if position < len(positional_order):
                filters[positional_order[position]] = token
                position += 1
    return entry_type, filters

@dp.message(Command("profiles"))
async def cmd_profiles(message: types.Message):
    if not is_admin(message.from_user.id):
        return
    
    if not parsing_profiles:
        await message.reply("‚ùå –ü—Ä–æ—Ñ–∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
        return
    
    text = "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏:\n\n"
    for key, profile in parsing_profiles.items():
        text += f"üî∏ `{key}` - {profile['name']}\n"
    
    await message.reply(text, parse_mode="Markdown")

@dp.message(Command("parse"))
async def cmd_parse(message: types.Message):
    if not is_admin(message.from_user.id):
        return
    
    args = message.text.split(" ", 1)
    if len(args) < 2:
        await message.reply("‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /parse <url>")
        return
    
    url = args[1]
    await message.reply(f"üîÑ –ü–∞—Ä—Å–∏–º {url}...")
    
    try:
        async with UniversalParser() as parser:
            results = await parser.parse_url(url)
        
        if results:
            save_results("manual_parse", results)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            preview = results[:5]
            text = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n\n"
            text += json.dumps(preview, ensure_ascii=False, indent=2)
            
            if len(text) > 4000:
                text = text[:3900] + "..."
            
            await message.reply(f"``````", parse_mode="Markdown")
        else:
            await message.reply("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
    except Exception as e:
        await message.reply(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

@dp.message(Command("run"))
async def cmd_run(message: types.Message):
    if not is_admin(message.from_user.id):
        return
    
    args = message.text.split(" ", 1)
    if len(args) < 2:
        await message.reply("‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /run <profile_name>")
        return
    
    profile_name = args[1]
    
    if profile_name not in parsing_profiles:
        await message.reply(f"‚ùå –ü—Ä–æ—Ñ–∏–ª—å '{profile_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    await message.reply(f"üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å '{profile_name}'...")
    
    try:
        async with UniversalParser() as parser:
            results = await parser.parse_by_profile(profile_name)
        
        if results:
            save_results(profile_name, results)
            
            text = f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å '{profile_name}' –≤—ã–ø–æ–ª–Ω–µ–Ω\n"
            text += f"–ù–∞–π–¥–µ–Ω–æ: {len(results)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n\n"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
            for i, result in enumerate(results[:3]):
                text += f"{i+1}. {json.dumps(result, ensure_ascii=False)}\n"
            
            if len(results) > 3:
                text += f"... –∏ –µ—â—ë {len(results)-3} —ç–ª–µ–º–µ–Ω—Ç–æ–≤"
            
            await message.reply(text)
        else:
            await message.reply("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
    except Exception as e:
        await message.reply(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

@dp.message(Command("results"))
async def cmd_results(message: types.Message):
    if not is_admin(message.from_user.id):
        return
    
    results = get_recent_results(limit=100)
    
    if not results:
        await message.reply("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    text = f"üìä –ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\n\n"
    
    for result in results[:10]:
        text += f"üî∏ {result['timestamp']} - {result['profile_name']}: {result['count']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n"
    
    await message.reply(text)

@dp.message(Command("export"))
async def cmd_export(message: types.Message):
    if not is_admin(message.from_user.id):
        return
    
    results = get_recent_results(limit=1000)
    
    if not results:
        await message.reply("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        return
    
    # –°–æ–∑–¥–∞—ë–º Excel —Ñ–∞–π–ª
    df = pd.DataFrame(results)
    
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Results')
    
    buffer.seek(0)
    
    file = BufferedInputFile(buffer.read(), filename="parsing_results.xlsx")
    await message.reply_document(file, caption=f"üìà –≠–∫—Å–ø–æ—Ä—Ç: {len(results)} –∑–∞–ø–∏—Å–µ–π")


@dp.message(Command("news"))
async def cmd_news(message: types.Message):
    if not is_admin(message.from_user.id):
        return

    filters = _parse_filters(message.text)
    news_items = await alert_checker.get_news(
        niche=filters["niche"], region=filters["region"], limit=5
    )

    if not news_items:
        await message.reply("‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    lines = [
        f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è {filters['niche']} / {filters['region']}",
        "",
    ]
    for idx, item in enumerate(news_items, start=1):
        lines.append(
            f"{idx}. {item['title']}\n–ò—Å—Ç–æ—á–Ω–∏–∫: {item['source']}\n"
            f"–î–∞—Ç–∞: {item['published_at']}\n–°—Å—ã–ª–∫–∞: {item['url']}"
        )
        if item.get("summary"):
            lines.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {item['summary']}")
        lines.append("")

    await message.reply("\n".join(lines[:20]))


@dp.message(Command("digest"))
async def cmd_digest(message: types.Message):
    if not is_admin(message.from_user.id):
        return

    filters = _parse_filters(message.text)
    digest = await alert_checker.build_digest(
        niche=filters["niche"], region=filters["region"], news_limit=3
    )

    lines = [
        f"üì¨ –î–∞–π–¥–∂–µ—Å—Ç –¥–ª—è {digest['niche']} / {digest['region']}",
        "",
        "–ù–æ–≤–æ—Å—Ç–∏:",
    ]

    if digest["news"]:
        for item in digest["news"]:
            lines.append(f"- {item['title']} ({item['source']})")
    else:
        lines.append("- –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç")

    lines.append("")
    lines.append("–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏:")
    for entry_type, info in digest["directories"].items():
        lines.append(f"- {entry_type}: {info['count']} –∑–∞–ø–∏—Å–µ–π")

    await message.reply("\n".join(lines))


@dp.message(Command("directory"))
async def cmd_directory(message: types.Message):
    if not is_admin(message.from_user.id):
        return

    entry_type, filters = _parse_directory_args(message.text)
    entries = await alert_checker.get_directory_entries(
        entry_type=entry_type, niche=filters["niche"], region=filters["region"], limit=10
    )

    if not entries:
        await message.reply("‚ùå –ó–∞–ø–∏—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    lines = [
        f"üìö {entry_type.capitalize()} –¥–ª—è {filters['niche']} / {filters['region']}",
        "",
    ]

    for entry in entries:
        lines.append(f"üî∏ {entry['name']} (–æ–±–Ω–æ–≤–ª–µ–Ω–æ {entry['updated_at']})")
        if entry.get("contact_info"):
            lines.append(f"–ö–æ–Ω—Ç–∞–∫—Ç—ã: {entry['contact_info']}")
        if entry.get("metadata"):
            lines.append(f"–î–µ—Ç–∞–ª–∏: {entry['metadata']}")
        lines.append("")

    await message.reply("\n".join(lines[:30]))

async def start_bot():
    print("ü§ñ Telegram –±–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(start_bot())
